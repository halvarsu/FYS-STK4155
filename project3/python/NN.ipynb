{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pde_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = pde_nn.DiffusionNN(verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.initialize() # to reset graph for each run of the cell\n",
    "print(net.X.size)\n",
    "net.add_layer(100, tf.nn.elu)\n",
    "# net.add_layer(100, tf.nn.sigmoid)\n",
    "net.add_layer(100, tf.nn.elu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Front cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import axes3d\n",
    "\n",
    "f = lambda x,t: np.sin(np.pi*x) * np.exp(-np.pi**2 * t)\n",
    "N = 100\n",
    "t = np.linspace(0,0.5,40)\n",
    "x = np.linspace(0,1,60)\n",
    "X,T = np.meshgrid(x,t)\n",
    "\n",
    "Z = f(X,T)\n",
    "\n",
    "norm = plt.Normalize(Z.min(), Z.max())\n",
    "colors = plt.cm.viridis(norm(Z))\n",
    "rcount, ccount, _ = colors.shape\n",
    "\n",
    "fig = plt.figure(figsize = [16,13], frameon = False)\n",
    "ax = fig.add_subplot(111, projection = '3d')\n",
    "surf = ax.plot_surface(X, T, Z, rcount=rcount, ccount=ccount,\n",
    "                       facecolors=colors, shade=False)\n",
    "surf.set_facecolor((0,0,0,0))\n",
    "\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_zticks([])\n",
    "plt.axis('off')\n",
    "\n",
    "ax.view_init(30, 40)\n",
    "fig.savefig('figures/front_cover.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt_kwargs = dict(momentum = 0.0,  use_nesterov = False)\n",
    "opt_kwargs = {} # dict(beta1 = 0.9)\n",
    "net.run(0.0001, 10000, optimizer = tf.train.AdamOptimizer, **opt_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_kwargs = {} # dict(momentum = 0.5,  use_nesterov = True)\n",
    "net.run(0.05, 10000, optimizer = tf.train.GradientDescentOptimizer, **opt_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "net.plot_error()\n",
    "fig.savefig('figures/error.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run a hyperparameter search with hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "def objective(params):\n",
    "    global i\n",
    "    print(i)\n",
    "    i = i + 1\n",
    "    net = pde_nn.DiffusionNN(verbose = False)\n",
    "    net.initialize() # to reset global graph variables\n",
    "    \n",
    "    \n",
    "    first    = params['first_layer']\n",
    "    last_rel     = params['last_layer_rel']\n",
    "    last = 10 +  (first - 10)*last_rel\n",
    "    n_hidden = params['n_hidden'] + 1\n",
    "    \n",
    "    layer_sizes = np.logspace(np.log10(first), np.log10(last), n_hidden)\n",
    "    \n",
    "    for size in layer_sizes:\n",
    "        net.add_layer(size, params['act_func'])\n",
    "        \n",
    "    print(params)\n",
    "    p = params['optimizer'].copy()\n",
    "    opt = p.pop('type')\n",
    "    opt_kwargs = p\n",
    "    learning_rate = 10**params['log_learning_rate']\n",
    "    final_cost = net.run(learning_rate = learning_rate,\n",
    "                         iterations = 10000,\n",
    "                         optimizer = opt, **opt_kwargs)\n",
    "    print(final_cost, net.mse[-1])\n",
    "    if np.isnan(final_cost):\n",
    "        final_cost = np.inf\n",
    "    return {'loss':final_cost, 'params':params, 'net':net, 'status': STATUS_OK}\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperopt_grid = {\n",
    "    'log_learning_rate' : hp.quniform('log_learning_rate', -5, -1, 1),\n",
    "    'first_layer'   : hp.quniform('first_layer', 10, 128, 2),\n",
    "    'last_layer_rel'    : hp.quniform('last_layer_rel', 0.1, 1, 0.01),\n",
    "    'n_hidden'      : hp.randint('n_hidden', 4), # +1 in the code\n",
    "    'act_func'      : hp.choice('act_func', [tf.nn.sigmoid, tf.nn.tanh, tf.nn.relu]),\n",
    "    'optimizer'     : hp.choice('optimizer', [{'type': tf.train.AdamOptimizer},\n",
    "                                             ])\n",
    "}       \n",
    "trials = Trials()\n",
    "results = fmin(objective, hyperopt_grid, algo = tpe.suggest,\n",
    "              trials = trials, max_evals = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperopt_grid_momentum = {\n",
    "    'log_learning_rate' : hp.quniform('log_learning_rate', -5, -1, 1),\n",
    "    'first_layer'   : hp.quniform('first_layer', 10, 128, 2),\n",
    "    'last_layer_rel'    : hp.quniform('last_layer_rel', 0.1, 1, 0.01),\n",
    "    'n_hidden'      : hp.randint('n_hidden', 4), # +1 in the code\n",
    "    'act_func'      : hp.choice('act_func', [tf.nn.sigmoid, tf.nn.tanh, tf.nn.relu]),\n",
    "    'optimizer'     : hp.choice('optimizer', [ {'type': tf.train.MomentumOptimizer, \n",
    "                                               'momentum': hp.quniform('momentum', 0, 1, 0.1), \n",
    "                                               'use_nesterov': hp.choice('use_nesterov', [False, True])}\n",
    "                                             ])}       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trials_mom = Trials()\n",
    "results_mom = fmin(objective, hyperopt_grid_momentum, algo = tpe.suggest,\n",
    "              trials = trials_mom, max_evals = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def add_layer_columns(df):\n",
    "    first = df['first_layer']\n",
    "    gamma_s  = df['last_layer_rel']\n",
    "    last  = 10 + (first - 10) * gamma_s\n",
    "    n_hidden = df['n_hidden'] + 1\n",
    "    sizes = []\n",
    "    for f,l,n in zip(first.values, last.values, n_hidden.values):\n",
    "        sizes.append(np.logspace(np.log10(f), np.log10(l), n, dtype = int))\n",
    "    df['layers'] = sizes\n",
    "    df['total_layer_size'] = [np.sum(v) for v in sizes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mom = pd.DataFrame(trials_mom.results)\n",
    "df_mom = pd.concat([df_mom, pd.DataFrame(list(df_mom['params']))], axis = 1, sort = False)\n",
    "df_mom['act_func_name'] = df_mom['act_func'].apply(lambda x:x.__name__)\n",
    "df_mom['mse'] = df_mom['net'].apply(lambda x: x.mse[-1])\n",
    "add_layer_columns(df_mom)\n",
    "i = np.argmin(df_mom.loss.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(df_mom.iloc[i]['net'].cost)\n",
    "plt.semilogy(df_mom.iloc[i]['net'].mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# print info on best adam net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_adam = pd.DataFrame(res)\n",
    "add_layer_columns(df_adam)\n",
    "df_adam['act_func_name'] =  df_adam['act_func'].apply(lambda x:x.__name__) \n",
    "\n",
    "# gather best nets of momentum-optimizer\n",
    "\n",
    "\n",
    "print('name,  size,  learning_rate')\n",
    "for name, item in df_adam.groupby('act_func_name'):\n",
    "    i = np.argmin(item.loss.values)\n",
    "    best = item.iloc[i]\n",
    "    print('=============')\n",
    "    print(name)\n",
    "    print('=============')\n",
    "    print('size', best['total_layer_size'])\n",
    "    print('nhid', best['n_hidden'])\n",
    "    print('lamb', best['log_learning_rate'])\n",
    "    print('cost', best['loss'])\n",
    "    print('mse ', best['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gather best nets of momentum-optimizer, and print info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_mom = []\n",
    "best_nets_mom = []\n",
    "print('name,  size,  learning_rate')\n",
    "for name, item in df_mom.groupby('act_func_name'):\n",
    "    i = np.argmin(item.loss.values)\n",
    "    best = item.iloc[i]\n",
    "    names_mom.append(name)\n",
    "    best_nets_mom.append(best['net'])\n",
    "    print('=============')\n",
    "    print(name)\n",
    "    print('=============')\n",
    "    print('size', best['total_layer_size'])\n",
    "    print('nhid', best['n_hidden'])\n",
    "    print('mome', best['optimizer']['momentum'])\n",
    "    print('use?', best['optimizer']['use_nesterov'])\n",
    "    print('lamb', best['log_learning_rate'])\n",
    "    print('cost', best['loss'])\n",
    "    print('mse ', best['mse'])\n",
    "best_nets_mom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost function as Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df_mom['optimizer'].apply(pd.Series)\n",
    "temp['loss'] = df_mom['loss']\n",
    "temp\n",
    "for nest, item in temp.groupby('use_nesterov'):\n",
    "    print(nest)\n",
    "    plt.semilogy(item['momentum'], item['loss'],'o', label = 'Nesterov = {}'.format(nest))\n",
    "    \n",
    "plt.ylabel('Cost')    \n",
    "plt.xlabel('Momentum')    \n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/nesterov_mom.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(df['loss'], 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(list(df['params']))\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = np.loadtxt('mse.txt')\n",
    "mse_best = np.argmin(mse)\n",
    "plt.semilogy(mse, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "    \n",
    "    \n",
    "import pandas as pd\n",
    "\n",
    "losses = trials.losses()\n",
    "loss_best = np.argmin(losses)\n",
    "res = []\n",
    "temp = _104\n",
    "\n",
    "for m, r in zip(mse, _104.copy()):# trials.results:\n",
    "    res.append(r['params'].copy())\n",
    "    res[-1]['act_func'] = res[-1]['act_func'] # .__name__\n",
    "    res[-1]['loss'] = r['loss']\n",
    "    res[-1]['mse'] = m\n",
    "    \n",
    "    # add info on layers\n",
    "    first   = res[-1]['first_layer']\n",
    "    gamma_s = res[-1]['last_layer_rel']\n",
    "    last = 10 + (first - 10)*gamma_s\n",
    "    \n",
    "    n_hidden = res[-1]['n_hidden'] + 1\n",
    "    layer_sizes = np.logspace(np.log10(first), np.log10(last), n_hidden,dtype=int)\n",
    "    res[-1]['layers'] = list(layer_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(res)\n",
    "   \n",
    "add_layer_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_funcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regenerate best network for Adam, as we didn't save networks at first run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_outs = {}\n",
    "for name, item in df.groupby('act_func'):\n",
    "    i_best = (item.sort_values(by = 'loss').iloc[0].name)\n",
    "    \n",
    "    p = trials.results[i_best]['params']\n",
    "    p['optimizer']['type'] = tf.train.AdamOptimizer\n",
    "    best_outs[name] = objective(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run one more time to also catch the network\n",
    "Was not implemented at time of initial run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = trials.results[loss_best]['params']\n",
    "p['optimizer']['type'] = tf.train.AdamOptimizer\n",
    "out = objective(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = _190 # how it actually was run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size':14})\n",
    "\n",
    "def plot_costs_and_mse(names, best_nets, filename = 'best', title=None):\n",
    "    \"\"\"Plots solution and mse of one network of each type\"\"\"\n",
    "\n",
    "\n",
    "    fig,axes = plt.subplots(len(names),figsize = [5,1 + 2*len(names)], sharex = True)\n",
    "    if title:\n",
    "        fig.suptitle(title)\n",
    "\n",
    "    for ax,name, net in zip(axes, names, best_nets):\n",
    "        # net = out['net']\n",
    "        ax.semilogy(net.cost, linewidth = 1)\n",
    "        ax.semilogy(net.mse, linewidth = 1)\n",
    "\n",
    "        ax.set_title(name)\n",
    "        ax.set_ylabel('Error')\n",
    "\n",
    "    axes[0].legend(['cost','mse'], loc = 'upper left')\n",
    "    axes[-1].set_xlabel('Iteration')\n",
    "    fig.tight_layout()\n",
    "    fig.savefig('figures/{}.pdf'.format(filename))\n",
    "\n",
    "best_nets_adam = []\n",
    "names_adam = []\n",
    "\n",
    "for name, out in  best_outs.items():\n",
    "    best_nets_adam.append(out['net'])\n",
    "    names_adam.append(name)\n",
    "plot_costs_and_mse(names_adam, best_nets_adam, filename = 'best_adam')\n",
    "plot_costs_and_mse(names_mom, best_nets_mom, filename = 'best_mom')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best run at $x \\sim 0.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size':14})\n",
    "plt.figure()\n",
    "x = best_nets_adam[2].X[0,10]\n",
    "t = np.linspace(0,1,20)\n",
    "analytic = np.sin(np.pi * x) * np.exp(-np.pi**2 * t)\n",
    "\n",
    "meshes = best_nets_adam[2].meshes[::8]\n",
    "\n",
    "col = np.linspace(0,1,len(meshes)+1 )[:-1]\n",
    "\n",
    "ax = plt.gca()\n",
    "for c, mesh in zip(col, meshes):\n",
    "    ax.semilogy(t, mesh[:,10], linewidth = 1.5, color = plt.cm.viridis(c))\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "ax.semilogy(t, analytic, '--', linewidth = 2, color = 'k', label = 'Analytical')\n",
    "ax.legend()\n",
    "\n",
    "ax.set_xlabel('Time (t)')\n",
    "ax.set_ylabel('Value at $x \\sim 0.5$')\n",
    "\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "cmap = mpl.cm.viridis\n",
    "norm = mpl.colors.Normalize(vmin=0, vmax=10000)\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "cb1 = mpl.colorbar.ColorbarBase(cax, cmap=cmap,\n",
    "                                norm=norm,\n",
    "                                orientation='vertical')\n",
    "cb1.set_label('Iteration')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/best_sol_convergence.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make images for animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = np.linspace(0,1,20)\n",
    "t = np.linspace(0,1,20)\n",
    "X,T = np.meshgrid(x,t)\n",
    "for i,mesh in enumerate(net.meshes):\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection = '3d')\n",
    "    \n",
    "    ax.set_title('{:0>4}'.format(i))\n",
    "    ax.plot_surface(X, T, mesh)\n",
    "    ax.set_zlim([0,1])\n",
    "    fig.savefig('figures/temp{:0>4}.png'.format(i))\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hist plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size':14})\n",
    "\n",
    "def plot_hist(df,  ax=None, sharex = False):\n",
    "    if ax is None:\n",
    "        fig = plt.figure()\n",
    "        ax = plt.gca()\n",
    "    else:\n",
    "        fig = plt.gcf()\n",
    "    df = df.sort_values(by = 'loss')\n",
    "\n",
    "    bins1 = np.linspace(-5,1.2,20)\n",
    "\n",
    "    for act, item in df.groupby('act_func_name'):\n",
    "        ax.hist(np.log10(item['loss']), bins = bins1,  label = act, histtype='step')\n",
    "\n",
    "    ticks = np.arange(-5,2)\n",
    "    ax.set_xticks(ticks)\n",
    "    ax.set_xticklabels([\"$10^{{{}}}$\".format(i) for i in ticks])\n",
    "    if not sharex:\n",
    "        ax.set_xlabel('Cost')\n",
    "    ax.set_ylabel('Count')\n",
    "\n",
    "    ax.legend(loc = 'upper center')\n",
    "    \n",
    "df = pd.DataFrame(res)\n",
    "df['act_func_name'] = df['act_func'].apply(lambda x:x.__name__)\n",
    "\n",
    "fig,[ax1,ax2] = plt.subplots(2,1, figsize = [5,6], sharex = True)\n",
    "plot_hist(df,  ax = ax1, sharex = True)\n",
    "ax1.set_title('Adam')\n",
    "plot_hist(df_mom,  ax = ax2)\n",
    "ax2.set_title('Momentum')\n",
    "plt.savefig('figures/hyper_hist.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(res)\n",
    "df = df.sort_values(by = 'loss')\n",
    "print(df[['act_func', 'layers', 'log_learning_rate', 'loss', 'mse']].head(5).to_latex(escape = None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(res)\n",
    "df = df.sort_values(by = 'mse')\n",
    "print(df[['act_func', 'layers', 'log_learning_rate', 'loss', 'mse']].head(5).to_latex(escape = None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_mom.sort_values(by='loss')[['act_func_name', 'layers', 'log_learning_rate', 'loss', 'mse']].head(5).to_latex(escape = None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_mom.sort_values(by='mse')[['act_func_name', 'layers', 'log_learning_rate', 'loss', 'mse']].head(5).to_latex(escape = None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Tensorflow-GPU)",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
